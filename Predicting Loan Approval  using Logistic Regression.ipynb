{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e958a03-ae1b-42af-a5fe-4f101c76117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (429, 10)\n",
      "Testing set shape: (185, 10)\n",
      "Preprocessed training shape: (429, 19)\n",
      "Preprocessed testing shape: (185, 19)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ============================\n",
    "# 1) Load Dataset\n",
    "# ============================\n",
    "df = pd.read_csv(\"train_u6lujuX_CVtuZ9i (1).csv\")\n",
    "\n",
    "# Drop Loan_ID (identifier)\n",
    "df.drop(columns=[\"Loan_ID\"], inplace=True)\n",
    "\n",
    "# Create TotalIncome feature\n",
    "df[\"TotalIncome\"] = df[\"ApplicantIncome\"] + df[\"CoapplicantIncome\"]\n",
    "\n",
    "# Convert Dependents \"3+\" ‚Üí \"3\"\n",
    "df[\"Dependents\"] = df[\"Dependents\"].replace(\"3+\", \"3\")\n",
    "\n",
    "# Map target variable: Y ‚Üí 1, N ‚Üí 0\n",
    "df[\"Loan_Status\"] = df[\"Loan_Status\"].map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "# ============================\n",
    "# 2) Select Features & Target\n",
    "# ============================\n",
    "features = [\n",
    "    \"Gender\", \"Married\", \"Dependents\", \"Education\", \"Self_Employed\",\n",
    "    \"Credit_History\", \"Property_Area\", \"LoanAmount\",\n",
    "    \"Loan_Amount_Term\", \"TotalIncome\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"Loan_Status\"]\n",
    "\n",
    "# ============================\n",
    "# 3) Define Numeric & Categorical Columns\n",
    "# ============================\n",
    "numeric_features = [\"LoanAmount\", \"Loan_Amount_Term\", \"TotalIncome\", \"Credit_History\"]\n",
    "categorical_features = [\"Gender\", \"Married\", \"Dependents\", \"Education\", \"Self_Employed\", \"Property_Area\"]\n",
    "\n",
    "# ============================\n",
    "# 4) Preprocessing Pipelines\n",
    "# ============================\n",
    "\n",
    "# Numeric pipeline ‚Üí impute (median) + scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline ‚Üí impute (most frequent) + OneHot Encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combined preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 5) Train/Test Split (70/30)\n",
    "# ============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "\n",
    "# ============================\n",
    "# 6) Fit Preprocessing Only\n",
    "# ============================\n",
    "X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "X_test_prepared = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Preprocessed training shape:\", X_train_prepared.shape)\n",
    "print(\"Preprocessed testing shape:\", X_test_prepared.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a8c7e3-4722-4008-aa50-a4413b73aa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8540540540540541\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# üìå Logistic Regression Model Training\n",
    "# =============================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) Create a full pipeline:\n",
    "#    - Preprocessing (that we built earlier)\n",
    "#    - Logistic Regression model\n",
    "# ---------------------------------------------------\n",
    "\n",
    "log_reg_model = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),          # ÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑŸÄ preprocessing ÿßŸÑÿ™Ÿä ÿπŸÖŸÑŸÜÿßŸáÿß\n",
    "    (\"classifier\", LogisticRegression())      # ŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑÿßŸÜÿ≠ÿØÿßÿ± ÿßŸÑŸÑŸàÿ¨ÿ≥ÿ™Ÿä\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) Train the model on training data\n",
    "# ---------------------------------------------------\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "# ÿ¥ÿ±ÿ≠: ŸáŸÜÿß Ÿäÿ™ŸÖ ÿ™ÿØÿ±Ÿäÿ® ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿπŸÑŸâ ÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ™ÿØÿ±Ÿäÿ® ÿ®ÿπÿØ ÿ™ÿ∑ÿ®ŸäŸÇ ŸÉŸÑ ÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑŸÄ preprocessing ÿπŸÑŸäŸáÿß.\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) Evaluate the model on test data\n",
    "# ---------------------------------------------------\n",
    "log_reg_accuracy = log_reg_model.score(X_test, y_test)\n",
    "# ÿ¥ÿ±ÿ≠: score Ÿäÿπÿ∑Ÿä ÿØŸÇÿ© ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ accuracy\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", log_reg_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0411cc44-763b-415f-a342-2fadab30a447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (L2) Accuracy: 0.8540540540540541\n",
      "Logistic Regression (L1) Accuracy: 0.8486486486486486\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# üìå Logistic Regression with Different Penalties (L1 & L2)\n",
    "# =====================================================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1) Logistic Regression with L2 regularization (default)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "log_reg_L2 = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200))\n",
    "])\n",
    "\n",
    "# Train\n",
    "log_reg_L2.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "acc_L2 = log_reg_L2.score(X_test, y_test)\n",
    "print(\"Logistic Regression (L2) Accuracy:\", acc_L2)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2) Logistic Regression with L1 regularization\n",
    "# -----------------------------------------------------\n",
    "# ŸÖŸÑÿßÿ≠ÿ∏ÿ©: penalty='l1' Ÿäÿ≠ÿ™ÿßÿ¨ solver ÿßÿ≥ŸÖŸá 'liblinear' ÿ£Ÿà 'saga'\n",
    "\n",
    "log_reg_L1 = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(penalty='l1', solver='liblinear', max_iter=200))\n",
    "])\n",
    "\n",
    "# Train\n",
    "log_reg_L1.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "acc_L1 = log_reg_L1.score(X_test, y_test)\n",
    "print(\"Logistic Regression (L1) Accuracy:\", acc_L1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47bf94a9-97be-46aa-bc95-6584ebf10b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression (L2 Penalty) =====\n",
      "Accuracy : 0.8540540540540541\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pos_label=Y is not a valid label. It should be one of [0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score :\u001b[39m\u001b[38;5;124m\"\u001b[39m, f1_score(y_true, y_pred, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 3) Evaluate both models\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m evaluate_model(y_test, y_pred_L2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression (L2 Penalty)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m evaluate_model(y_test, y_pred_L1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression (L1 Penalty)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(y_true, y_pred, model_name)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m===== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m =====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy :\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_true, y_pred))\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision:\u001b[39m\u001b[38;5;124m\"\u001b[39m, precision_score(y_true, y_pred, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall   :\u001b[39m\u001b[38;5;124m\"\u001b[39m, recall_score(y_true, y_pred, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score :\u001b[39m\u001b[38;5;124m\"\u001b[39m, f1_score(y_true, y_pred, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2182\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   2015\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   2016\u001b[0m     {\n\u001b[0;32m   2017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2042\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2043\u001b[0m ):\n\u001b[0;32m   2044\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   2045\u001b[0m \n\u001b[0;32m   2046\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2180\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   2181\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2182\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   2183\u001b[0m         y_true,\n\u001b[0;32m   2184\u001b[0m         y_pred,\n\u001b[0;32m   2185\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   2186\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[0;32m   2187\u001b[0m         average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[0;32m   2188\u001b[0m         warn_for\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[0;32m   2189\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   2190\u001b[0m         zero_division\u001b[38;5;241m=\u001b[39mzero_division,\n\u001b[0;32m   2191\u001b[0m     )\n\u001b[0;32m   2192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1767\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1605\u001b[0m \n\u001b[0;32m   1606\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m _check_zero_division(zero_division)\n\u001b[1;32m-> 1767\u001b[0m labels \u001b[38;5;241m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1769\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1770\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1547\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m present_labels:\n\u001b[0;32m   1546\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(present_labels) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1547\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1548\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_label=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpos_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid label. It \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpresent_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1550\u001b[0m             )\n\u001b[0;32m   1551\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [pos_label]\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: pos_label=Y is not a valid label. It should be one of [0, 1]"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# üìå Evaluate Logistic Regression Models (L1 & L2)\n",
    "# ===========================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1) Predict using both models\n",
    "# ------------------------------------------------\n",
    "\n",
    "y_pred_L2 = log_reg_L2.predict(X_test)\n",
    "y_pred_L1 = log_reg_L1.predict(X_test)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) Define a function to print evaluation metrics\n",
    "# ------------------------------------------------\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, pos_label=\"Y\"))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, pos_label=\"Y\"))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, pos_label=\"Y\"))\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Evaluate both models\n",
    "# ------------------------------------------------\n",
    "\n",
    "evaluate_model(y_test, y_pred_L2, \"Logistic Regression (L2 Penalty)\")\n",
    "evaluate_model(y_test, y_pred_L1, \"Logistic Regression (L1 Penalty)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f48c73-b501-44f0-ae1d-770be9083ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression (L2 Penalty) =====\n",
      "Accuracy : 0.8540540540540541\n",
      "Precision: 0.8333333333333334\n",
      "Recall   : 0.984251968503937\n",
      "F1 Score : 0.9025270758122743\n",
      "\n",
      "===== Logistic Regression (L1 Penalty) =====\n",
      "Accuracy : 0.8486486486486486\n",
      "Precision: 0.8278145695364238\n",
      "Recall   : 0.984251968503937\n",
      "F1 Score : 0.8992805755395683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict\n",
    "y_pred_L2 = log_reg_L2.predict(X_test)\n",
    "y_pred_L1 = log_reg_L1.predict(X_test)\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, pos_label=1))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, pos_label=1))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, pos_label=1))\n",
    "\n",
    "# Evaluate both models\n",
    "evaluate_model(y_test, y_pred_L2, \"Logistic Regression (L2 Penalty)\")\n",
    "evaluate_model(y_test, y_pred_L1, \"Logistic Regression (L1 Penalty)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aca5c0b-31b0-4a11-88b1-aab94ca94f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters: {'classifier__C': 0.01, 'classifier__penalty': 'l2'}\n",
      "Best CV Accuracy: 0.7924760601915185\n",
      "\n",
      "Test set evaluation:\n",
      "Accuracy : 0.8486486486486486\n",
      "Precision: 0.8278145695364238\n",
      "Recall   : 0.984251968503937\n",
      "F1 Score : 0.8992805755395683\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 32  26]\n",
      " [  2 125]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9412    0.5517    0.6957        58\n",
      "           1     0.8278    0.9843    0.8993       127\n",
      "\n",
      "    accuracy                         0.8486       185\n",
      "   macro avg     0.8845    0.7680    0.7975       185\n",
      "weighted avg     0.8634    0.8486    0.8354       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# --------------------------------------------\n",
    "# 1) Define pipeline (preprocessing + classifier)\n",
    "# --------------------------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(solver='liblinear', max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "# --------------------------------------------\n",
    "# 2) Define hyperparameter grid\n",
    "# --------------------------------------------\n",
    "param_grid = {\n",
    "    \"classifier__penalty\": [\"l1\", \"l2\"],   # ŸÜŸàÿπ ÿßŸÑŸÄ Regularization\n",
    "    \"classifier__C\": [0.01, 0.1, 1, 10, 100]  # ŸÇŸàÿ© ÿßŸÑŸÄ regularization\n",
    "}\n",
    "\n",
    "# --------------------------------------------\n",
    "# 3) Setup GridSearchCV\n",
    "# --------------------------------------------\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',   # ŸäŸÖŸÉŸÜ ÿ™ÿ∫ŸäŸäÿ±Ÿá ÿ•ŸÑŸâ 'roc_auc' ÿ•ÿ∞ÿß ÿ£ÿ±ÿØÿ™\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 4) Train model (fit GridSearchCV)\n",
    "# --------------------------------------------\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 5) Best parameters and score\n",
    "# --------------------------------------------\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid.best_score_)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 6) Evaluate on test set\n",
    "# --------------------------------------------\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"\\nTest set evaluation:\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, pos_label=1))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred, pos_label=1))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred, pos_label=1))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af2e6f7c-4cca-4a47-a64c-b1b45db2bc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Best parameters: {'classifier__C': 0.01, 'classifier__l1_ratio': 0, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Best CV Accuracy: 0.7924760601915185\n",
      "\n",
      "Test set evaluation:\n",
      "Accuracy : 0.8486486486486486\n",
      "Precision: 0.8278145695364238\n",
      "Recall   : 0.984251968503937\n",
      "F1 Score : 0.8992805755395683\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 32  26]\n",
      " [  2 125]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9412    0.5517    0.6957        58\n",
      "           1     0.8278    0.9843    0.8993       127\n",
      "\n",
      "    accuracy                         0.8486       185\n",
      "   macro avg     0.8845    0.7680    0.7975       185\n",
      "weighted avg     0.8634    0.8486    0.8354       185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "100 fits failed out of a total of 400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.68766074 0.79247606 0.79247606        nan 0.68766074 0.79247606\n",
      " 0.68766074        nan 0.68766074 0.79247606 0.68766074        nan\n",
      " 0.68766074 0.79247606 0.68766074        nan 0.79247606 0.79247606\n",
      " 0.79247606        nan 0.79247606 0.79247606 0.79247606        nan\n",
      " 0.79247606 0.79247606 0.79247606        nan 0.79247606 0.79247606\n",
      " 0.79247606        nan 0.79247606 0.78311902 0.78311902        nan\n",
      " 0.79247606 0.78311902 0.79015048        nan 0.79247606 0.78311902\n",
      " 0.79015048        nan 0.79247606 0.78311902 0.79247606        nan\n",
      " 0.78311902 0.78311902 0.78311902        nan 0.78311902 0.78311902\n",
      " 0.78311902        nan 0.78311902 0.78311902 0.78311902        nan\n",
      " 0.78311902 0.78311902 0.78311902        nan 0.78311902 0.78311902\n",
      " 0.78311902        nan 0.78311902 0.78311902 0.78311902        nan\n",
      " 0.78311902 0.78311902 0.78311902        nan 0.78311902 0.78311902\n",
      " 0.78311902        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) Define pipeline (preprocessing + LogisticRegression)\n",
    "# ---------------------------------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) Define hyperparameter grid\n",
    "# ---------------------------------------------------\n",
    "param_grid = {\n",
    "    \"classifier__penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],    # ÿ£ŸÜŸàÿßÿπ regularization\n",
    "    \"classifier__C\": [0.01, 0.1, 1, 10, 100],                    # ŸÇŸàÿ© regularization\n",
    "    \"classifier__solver\": [\"saga\"],                               # 'saga' ŸäÿØÿπŸÖ elasticnet Ÿà l1/l2\n",
    "    \"classifier__l1_ratio\": [0, 0.5, 0.7, 1]                     # ŸÅŸÇÿ∑ ŸÑŸÄ elasticnet\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) Setup GridSearchCV\n",
    "# ---------------------------------------------------\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',      # ŸäŸÖŸÉŸÜ ÿ™ÿ∫ŸäŸäÿ±Ÿá ÿ•ŸÑŸâ 'roc_auc' ÿ≠ÿ≥ÿ® ÿßŸÑÿ±ÿ∫ÿ®ÿ©\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) Train model (fit GridSearchCV)\n",
    "# ---------------------------------------------------\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5) Best parameters & best CV score\n",
    "# ---------------------------------------------------\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid.best_score_)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6) Evaluate on test set\n",
    "# ---------------------------------------------------\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"\\nTest set evaluation:\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, pos_label=1))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred, pos_label=1))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred, pos_label=1))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "906cc429-cb13-403a-a796-e4976e78d483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "===== Best Parameters =====\n",
      "{'classifier__C': 0.01, 'classifier__l1_ratio': 0, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Best Cross-Validation Accuracy: 0.7924760601915185\n",
      "\n",
      "===== Test Set Evaluation =====\n",
      "Accuracy : 0.8486486486486486\n",
      "Precision: 0.8278145695364238\n",
      "Recall   : 0.984251968503937\n",
      "F1 Score : 0.8992805755395683\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 32  26]\n",
      " [  2 125]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9412    0.5517    0.6957        58\n",
      "           1     0.8278    0.9843    0.8993       127\n",
      "\n",
      "    accuracy                         0.8486       185\n",
      "   macro avg     0.8845    0.7680    0.7975       185\n",
      "weighted avg     0.8634    0.8486    0.8354       185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "100 fits failed out of a total of 400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.68766074 0.79247606 0.79247606        nan 0.68766074 0.79247606\n",
      " 0.68766074        nan 0.68766074 0.79247606 0.68766074        nan\n",
      " 0.68766074 0.79247606 0.68766074        nan 0.79247606 0.79247606\n",
      " 0.79247606        nan 0.79247606 0.79247606 0.79247606        nan\n",
      " 0.79247606 0.79247606 0.79247606        nan 0.79247606 0.79247606\n",
      " 0.79247606        nan 0.79247606 0.78311902 0.78311902        nan\n",
      " 0.79247606 0.78311902 0.79015048        nan 0.79247606 0.78311902\n",
      " 0.79015048        nan 0.79247606 0.78311902 0.79247606        nan\n",
      " 0.78311902 0.78311902 0.78311902        nan 0.78311902 0.78311902\n",
      " 0.78311902        nan 0.78311902 0.78311902 0.78311902        nan\n",
      " 0.78311902 0.78311902 0.78311902        nan 0.78311902 0.78311902\n",
      " 0.78311902        nan 0.78311902 0.78311902 0.78311902        nan\n",
      " 0.78311902 0.78311902 0.78311902        nan 0.78311902 0.78311902\n",
      " 0.78311902        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\LEGION\\.anaconda\\anacoda 4\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1) Pipeline (Preprocessing + Logistic Regression)\n",
    "# ---------------------------------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) Hyperparameter grid\n",
    "# ---------------------------------------------------\n",
    "param_grid = {\n",
    "    \"classifier__penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],  # ÿ£ŸÜŸàÿßÿπ regularization\n",
    "    \"classifier__C\": [0.01, 0.1, 1, 10, 100],                  # ŸÇŸàÿ© regularization\n",
    "    \"classifier__solver\": [\"saga\"],                             # saga ŸäÿØÿπŸÖ elasticnet Ÿà l1/l2\n",
    "    \"classifier__l1_ratio\": [0, 0.5, 0.7, 1]                   # ŸÅŸÇÿ∑ ŸÑŸÄ elasticnet\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) GridSearchCV with stratified folds for balanced splits\n",
    "# ---------------------------------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) Fit GridSearchCV\n",
    "# ---------------------------------------------------\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5) Best parameters and CV score\n",
    "# ---------------------------------------------------\n",
    "print(\"===== Best Parameters =====\")\n",
    "print(grid.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid.best_score_)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6) Evaluate best model on test set\n",
    "# ---------------------------------------------------\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n===== Test Set Evaluation =====\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, pos_label=1))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred, pos_label=1))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred, pos_label=1))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e368e2cb-4797-4794-af84-9c4cb96b8876",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_reg_EN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 1) Define models to compare\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[0;32m      8\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression L2\u001b[39m\u001b[38;5;124m\"\u001b[39m: log_reg_L2,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression L1\u001b[39m\u001b[38;5;124m\"\u001b[39m: log_reg_L1,\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression ElasticNet\u001b[39m\u001b[38;5;124m\"\u001b[39m: log_reg_EN,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m: decision_tree_model\n\u001b[0;32m     13\u001b[0m }\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 2) Calculate metrics for each model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[0;32m     18\u001b[0m metrics_summary \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'log_reg_EN' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# ==============================\n",
    "# 1) Define models to compare\n",
    "# ==============================\n",
    "models = {\n",
    "    \"Logistic Regression L2\": log_reg_L2,\n",
    "    \"Logistic Regression L1\": log_reg_L1,\n",
    "    \"Logistic Regression ElasticNet\": log_reg_EN,\n",
    "    \"Decision Tree\": decision_tree_model\n",
    "}\n",
    "\n",
    "# ==============================\n",
    "# 2) Calculate metrics for each model\n",
    "# ==============================\n",
    "metrics_summary = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    metrics_summary.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, pos_label=1),\n",
    "        \"Recall\": recall_score(y_test, y_pred, pos_label=1),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, pos_label=1)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_summary)\n",
    "print(metrics_df)\n",
    "\n",
    "# ==============================\n",
    "# 3) Bar plot of metrics\n",
    "# ==============================\n",
    "metrics_melted = metrics_df.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=metrics_melted, x=\"Model\", y=\"Score\", hue=\"Metric\")\n",
    "plt.title(\"Comparison of Performance Metrics\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.show()\n",
    "\n",
    "# ==============================\n",
    "# 4) Confusion Matrix for each model\n",
    "# ==============================\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472d289-6162-424b-aaf8-0fd00a5ffece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
